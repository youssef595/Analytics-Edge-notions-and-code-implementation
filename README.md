# Analytics-Edge-notions-and-code-implementation
This is a repository for everyone aiming to design a good learning path in analytics and data science concepts. I will make sure to feed the repository with efficient code implementations and tips. Also, other sections will be added in the resources such as text analytics.

![General ML picture](https://github.com/youssef595/Analytics-Edge-notions-and-code-implementation/blob/main/newplot.png)

## Resources :
### Linear Regression :
* [Linear Regression from concept to code](https://towardsdatascience.com/the-concepts-behind-linear-regression-and-its-implementation-ffbab5a4d65e)
* [Multiple Linear Regression in brief](https://towardsdatascience.com/understanding-multiple-regression-249b16bde83e)
* [How to interpret OLS regression librarie's report](https://www.geeksforgeeks.org/interpreting-the-results-of-linear-regression-using-ols-summary/)
* [Understanding T-test and Anova test](https://youtu.be/NF5_btOaCig?list=PLblh5JKOoLUIzaEkCLIUxQFjPIlapw8nU)
* [Evaluation metric : Rsquared explanation](https://youtu.be/2AQKmw14mHM?list=PLblh5JKOoLUIzaEkCLIUxQFjPIlapw8nU)

### Logistic Regression (Classification) :
* [Logistic Regression from useful maths to code](https://towardsdatascience.com/logistic-regression-detailed-overview-46c4da4303bc)
* [LR maximum likelihood approach, optional](https://youtu.be/BfKanl1aSG0)
* [Tuning logistic regression parameter](https://www.kaggle.com/joparga3/2-tuning-parameters-for-logistic-regression)

### Tree based models :
* [Decision trees explained](https://www.youtube.com/watch?v=7VeUPuFGJHk&list=PLBq2sVJiEBvA9rPo3IEQsJNI4IJbn81tB&index=1=)
* [Interpreting a decision tree in python](https://towardsdatascience.com/understanding-decision-trees-for-classification-python-9663d683c952)
* [Regression Trees explained](https://www.youtube.com/watch?v=g9c66TUylZ4&list=PLBq2sVJiEBvA9rPo3IEQsJNI4IJbn81tB&index=5)
* [Pruning Regression Trees (try to avoid overfitting)](https://www.youtube.com/watch?v=D0efHEJsfHo&list=PLBq2sVJiEBvA9rPo3IEQsJNI4IJbn81tB&index=6)
* [Tradeoff between Bias and variance](https://www.youtube.com/watch?v=EuBBz3bI-aA)
* [Ensembling Methods (bagging vs boosting)](https://towardsdatascience.com/ensemble-methods-bagging-boosting-and-stacking-c9214a10a205)
* [Random Forest explained](https://youtu.be/3CC4N4z3GJc?list=PLBq2sVJiEBvA9rPo3IEQsJNI4IJbn81tB)
* [Adaboost explained](https://www.youtube.com/watch?v=LsK-xG1cLYA&list=PLBq2sVJiEBvA9rPo3IEQsJNI4IJbn81tB&index=8)
* [Gradient Boost Part1](https://youtu.be/3CC4N4z3GJc?list=PLBq2sVJiEBvA9rPo3IEQsJNI4IJbn81tB)
* [Gradient Boost Part2](https://www.youtube.com/watch?v=2xudPOBz-vs)
* [Gradient Boost Part3](https://www.youtube.com/watch?v=jxuNLH5dXCs&t=5s)
* [Gradient Boost Part4](https://www.youtube.com/watch?v=StWY5QWMXCw)
* [Exterme Gradient Boost(XGBOOST) Part1](https://www.youtube.com/watch?v=OtD8wVaFm6E&t=1259s)
* [Exterme Gradient Boost(XGBOOST) Part2](https://www.youtube.com/watch?v=8b1JEDvenQU)
* [Exterme Gradient Boost(XGBOOST) Part3](https://www.youtube.com/watch?v=ZVFeW798-2I)
* [Exterme Gradient Boost(XGBOOST) Part4](https://www.youtube.com/watch?v=oRrKeUCEbq8)

### Clustering:
* [Centroid Based clustering : Kmeans (Methods and drawbacks)](https://towardsdatascience.com/k-means-clustering-algorithm-applications-evaluation-methods-and-drawbacks-aa03e644b48a)
* [Connectivity Based clustering : Hierarchical clustering (How does it work)](https://youtu.be/7xHsRkOdVwo)
* [Density Based clustering : DBSCAN (DBSCAN vs Kmeans)](https://towardsdatascience.com/k-means-vs-dbscan-clustering-49f8e627de27)
* [Distribution Based clustering : Gaussian mixture models (base steps)](https://youtu.be/q71Niz856KE)
* [Kmeans vs Hierarchical vs DBSCAN vs GMM summary](https://towardsdatascience.com/k-means-dbscan-gmm-agglomerative-clustering-mastering-the-popular-models-in-a-segmentation-c891a3818e29)
